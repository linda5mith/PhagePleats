Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job             count
------------  -------
easy_cluster        1
pool_pdbs           1
total               2

Resources before job selection: {'_cores': 4, '_nodes': 9223372036854775807}
Ready jobs (1)
Select jobs to execute...
Using greedy selector because only single job has to be scheduled.
Selected jobs (1)
Resources after job selection: {'_cores': 3, '_nodes': 9223372036854775806}

[Thu Aug  1 18:37:36 2024]
rule pool_pdbs:
    input: /home/administrator/phd/crAss_DB/folds, /home/administrator/phd/PhagePleats/cluster_reps
    output: /home/administrator/phd/PhagePleats/pooled_pdbs
    jobid: 1
    reason: Set of input files has changed since last execution
    resources: tmpdir=/tmp

[Thu Aug  1 18:38:04 2024]
Finished job 1.
1 of 2 steps (50%) done
Resources before job selection: {'_cores': 4, '_nodes': 9223372036854775807}
Ready jobs (1)
Select jobs to execute...
Using greedy selector because only single job has to be scheduled.
Selected jobs (1)
Resources after job selection: {'_cores': 3, '_nodes': 9223372036854775806}

[Thu Aug  1 18:38:04 2024]
rule easy_cluster:
    input: /home/administrator/phd/PhagePleats/pooled_pdbs, /home/administrator/phd/PhagePleats/foldseek_out
    output: tmp
    log: /home/administrator/phd/PhagePleats/logs/result_cluster.log
    jobid: 0
    reason: Input files updated by another job: /home/administrator/phd/PhagePleats/pooled_pdbs
    resources: tmpdir=/tmp

Full Traceback (most recent call last):
  File "/home/administrator/programs/miniforge3/envs/CaudoAuto/lib/python3.10/site-packages/snakemake/scheduler.py", line 650, in _finish_jobs
    self.get_executor(job).handle_job_success(job)
  File "/home/administrator/programs/miniforge3/envs/CaudoAuto/lib/python3.10/site-packages/snakemake/executors/__init__.py", line 730, in handle_job_success
    super().handle_job_success(job)
  File "/home/administrator/programs/miniforge3/envs/CaudoAuto/lib/python3.10/site-packages/snakemake/executors/__init__.py", line 293, in handle_job_success
    job.postprocess(
  File "/home/administrator/programs/miniforge3/envs/CaudoAuto/lib/python3.10/site-packages/snakemake/jobs.py", line 1178, in postprocess
    self.dag.check_and_touch_output(
  File "/home/administrator/programs/miniforge3/envs/CaudoAuto/lib/python3.10/site-packages/snakemake/dag.py", line 630, in check_and_touch_output
    raise ImproperOutputException(job, [f])
snakemake.exceptions.ImproperOutputException: Outputs of incorrect type (directories when expecting files or vice versa). Output directories must be flagged with directory(). for rule easy_cluster:
    output: tmp
    affected files:
        tmp

ImproperOutputException in rule easy_cluster in file /home/administrator/phd/PhagePleats/Snakefile, line 33:
Outputs of incorrect type (directories when expecting files or vice versa). Output directories must be flagged with directory(). for rule easy_cluster:
    output: tmp
    affected files:
        tmp
Removing output files of failed job easy_cluster since they might be corrupted:
tmp
Skipped removing non-empty directory tmp
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-08-01T183735.868693.snakemake.log
unlocking
removing lock
removing lock
removed all locks
