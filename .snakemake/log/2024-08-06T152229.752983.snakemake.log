Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job                  count
-----------------  -------
run_python_script        1
total                    1

Select jobs to execute...

[Tue Aug  6 15:22:29 2024]
rule run_python_script:
    input: /home/administrator/phd/PhagePleats_out/foldseek_out/search_result.tsv, data/presence_absence_c_40_tm_30_4100.csv
    output: script_completed.txt
    jobid: 0
    reason: Set of input files has changed since last execution; Code has changed since last execution
    resources: tmpdir=/tmp

Touching output file script_completed.txt.
[Tue Aug  6 15:22:30 2024]
Finished job 0.
1 of 1 steps (100%) done
Complete log: .snakemake/log/2024-08-06T152229.752983.snakemake.log
