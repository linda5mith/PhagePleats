Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job                  count
-----------------  -------
run_python_script        1
total                    1

Select jobs to execute...

[Tue Aug  6 15:18:03 2024]
rule run_python_script:
    input: /home/administrator/phd/PhagePleats_out/foldseek_out/search_result.tsv
    output: script_completed.txt
    jobid: 0
    reason: Code has changed since last execution
    resources: tmpdir=/tmp

[Tue Aug  6 15:18:04 2024]
Error in rule run_python_script:
    jobid: 0
    input: /home/administrator/phd/PhagePleats_out/foldseek_out/search_result.tsv
    output: script_completed.txt

RuleException:
CalledProcessError in file /home/administrator/phd/PhagePleats/Snakefile, line 85:
Command 'mkdir -p /home/administrator/phd/PhagePleats_out &&  /home/administrator/programs/miniforge3/envs/CaudoAuto/bin/python3.10 /home/administrator/phd/PhagePleats/.snakemake/scripts/tmp71xfsqak.phagepleats.py' returned non-zero exit status 1.
  File "/home/administrator/phd/PhagePleats/Snakefile", line 85, in __rule_run_python_script
  File "/home/administrator/programs/miniforge3/envs/CaudoAuto/lib/python3.10/concurrent/futures/thread.py", line 58, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-08-06T151803.624434.snakemake.log
