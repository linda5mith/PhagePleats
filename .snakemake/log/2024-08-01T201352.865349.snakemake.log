Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job             count
------------  -------
easy_cluster        1
total               1

Resources before job selection: {'_cores': 4, '_nodes': 9223372036854775807}
Ready jobs (1)
Select jobs to execute...
Using greedy selector because only single job has to be scheduled.
Selected jobs (1)
Resources after job selection: {'_cores': 3, '_nodes': 9223372036854775806}

[Thu Aug  1 20:13:53 2024]
rule easy_cluster:
    input: /home/administrator/phd/PhagePleats/pooled_pdbs, /home/administrator/phd/PhagePleats/foldseek_out
    output: tmp
    log: /home/administrator/phd/PhagePleats/logs/result_cluster.log
    jobid: 0
    reason: Missing output files: tmp
    resources: tmpdir=/tmp

[Thu Aug  1 20:26:02 2024]
Finished job 0.
1 of 1 steps (100%) done
Complete log: .snakemake/log/2024-08-01T201352.865349.snakemake.log
unlocking
removing lock
removing lock
removed all locks
